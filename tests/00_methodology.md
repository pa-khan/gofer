# Методология тестирования Gofer MCP Tools

## Метрики оценки

### 1. Работоспособность (Functionality)
- ✅ **Работает** - инструмент выполняет задачу без ошибок
- ⚠️ **Работает с ограничениями** - работает, но есть нюансы
- ❌ **Не работает** - ошибка или неожиданное поведение

### 2. Точность (Accuracy) - НОВАЯ МЕТРИКА
Оценивается по шкале 0-100%:

#### Для операций чтения/поиска:
- **100%** - возвращает полностью корректные данные
- **90-99%** - незначительные отличия в форматировании
- **70-89%** - пропущены некоторые детали, но суть верна
- **50-69%** - значительные пропуски или неточности
- **0-49%** - большинство данных неверны или отсутствуют

#### Для операций поиска:
- **100%** - нашёл все релевантные результаты, нет ложных срабатываний
- **90-99%** - нашёл почти всё, 1-2 ложных срабатывания
- **70-89%** - пропустил 10-30% релевантных результатов
- **50-69%** - пропустил 30-50% результатов или много ложных срабатываний
- **0-49%** - неверные или нерелевантные результаты

#### Для операций парсинга (символы, типы, функции):
- **100%** - извлечены все символы/типы с полной информацией
- **90-99%** - пропущены 1-2 незначительных элемента
- **70-89%** - пропущены некоторые элементы или детали
- **50-69%** - значительные пропуски в структуре
- **0-49%** - неверная структура или большинство элементов пропущено

#### Для операций модификации (patch, edit, write):
- **100%** - изменения применены точно как ожидалось
- **90-99%** - незначительные отличия в форматировании
- **70-89%** - основные изменения есть, но есть артефакты
- **50-69%** - изменения частичны или с ошибками
- **0-49%** - изменения не применены или сломали код

### 3. Количество операций (Operations Count)
- Сколько вызовов инструментов требуется для выполнения задачи
- **Меньше = лучше** (эффективность)

### 4. Количество токенов (Token Usage)
- Общее количество токенов в запросе + ответе
- **Меньше = лучше** (экономичность)
- Измеряется для одной итерации

### 5. Скорость работы (Performance)
- Время выполнения операции в миллисекундах
- **Меньше = лучше** (быстродействие)
- Среднее значение из 5 измерений

---

## Структура тестирования

Каждый инструмент тестируется **5 раз** с разными сценариями:

1. **Базовый сценарий** - стандартное использование
2. **Граничные случаи** - большие файлы, сложные запросы
3. **Крайние случаи** - пустые данные, edge cases
4. **Ошибочные сценарии** - несуществующие файлы, неверные параметры
5. **Сложный сценарий** - комбинированное использование

---

## Формат отчёта

Каждый отчёт содержит:

### Заголовок теста
- Название инструментов (Gofer vs Native)
- Описание задачи

### 5 итераций тестирования
Для каждой итерации:
- **Сценарий**: описание теста
- **Параметры**: входные данные
- **Результат**: что вернул инструмент
- **Работоспособность**: ✅/⚠️/❌
- **Точность**: процент (0-100%)
- **Критерии точности**: почему именно такая оценка
- **Количество операций**: число
- **Количество токенов**: число
- **Скорость**: миллисекунды

### Сводная таблица
| Метрика | Gofer MCP | Native | Победитель |
|---------|-----------|--------|------------|

### Детальный анализ точности
- Что учитывалось при оценке точности
- Конкретные примеры различий
- Ложные срабатывания/пропуски (для поиска)

### Выводы
- Когда использовать Gofer
- Когда использовать Native
- Общий рейтинг

---

## Пример оценки точности

### Пример 1: Поиск "LRU cache"
**Gofer search:**
- Нашёл 5 результатов
- Все релевантны
- Упорядочены по релевантности
- **Точность: 100%**

**Native Grep:**
- Нашёл 4 результата по точному совпадению "pub struct LruCache"
- Пропустил использование LruCache в других контекстах
- Не нашёл семантически похожие концепции
- **Точность: 60%** (нашёл только точные совпадения, пропустил контекст)

### Пример 2: Чтение файла с диапазоном строк
**Gofer read_file:**
- Вернул строки 1-50 точно
- Правильные номера строк в метаданных
- Содержимое идентично оригиналу
- **Точность: 100%**

**Native Read:**
- Вернул строки 1-50 точно
- Содержимое идентично оригиналу
- **Точность: 100%**

### Пример 3: Извлечение символов
**Gofer get_symbols:**
- Нашёл все 47 символов в файле
- Указал типы (struct, impl, fn)
- Указал диапазоны строк
- **Точность: 100%**

**Native manual parsing:**
- Требует несколько операций Grep
- Может пропустить вложенные символы
- Нет информации о типах автоматически
- **Точность: 75%** (базовая информация есть, детали требуют дополнительной работы)

---

## Критерии победителя

Инструмент считается победителем, если:

1. **Общая эффективность**: (Точность × Скорость) / (Токены × Операции)
2. **Точность > 90%** обязательна для победы
3. При равной точности учитывается:
   - Скорость (вес 30%)
   - Токены (вес 30%)
   - Удобство API (вес 20%)
   - Дополнительные возможности (вес 20%)

---

## Типы тестируемых инструментов

### Категория 1: Чтение данных
- `read_file` vs `Read`
- `skeleton` vs ручной анализ
- `read_function_context` vs множественные операции
- `read_types_only` vs Grep + парсинг

### Категория 2: Поиск
- `search` (semantic) vs `Grep` (regex)
- `search_by_purpose` vs ручной поиск
- `search_symbols` vs Grep по сигнатурам
- `find_files` vs `Glob`

### Категория 3: Навигация по коду
- `get_symbols` vs tree-sitter парсинг
- `get_references` vs Grep
- `get_callers` / `get_callees` vs ручной анализ
- `rust_goto_definition` vs текстовый поиск

### Категория 4: Модификация
- `patch_file` vs `Edit`
- `write_file` vs `Write`
- `extract_to_hash` + `insert_hash` vs копирование текста

### Категория 5: Git операции
- `git_diff` vs Bash git diff
- `git_blame` vs Bash git blame
- `suggest_commit` vs ручное написание

### Категория 6: Rust-специфичные
- `rust_diagnostics` vs cargo check
- `rust_goto_definition` vs ручной поиск
- `rust_find_references` vs grep
- `rust_hover` vs чтение документации

---

## Валидация точности

Для каждого теста:

1. **Эталонный результат**: определить, что является 100% правильным ответом
2. **Сравнение**: посчитать метрики:
   - Precision = найденные релевантные / все найденные
   - Recall = найденные релевантные / все релевантные
   - Accuracy = правильные элементы / все элементы
3. **Документирование**: записать конкретные примеры различий
4. **Повторяемость**: тест должен давать одинаковые результаты при повторении

